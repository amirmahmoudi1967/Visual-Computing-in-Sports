{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2948a131",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <h1>Football field Analysis</h1>\n",
    "    <b>VIC Project, Main Code</b><br>\n",
    "    <i>Coded By Chloé DAEMS, Amir MAHMOUDI & Anne-Claire LAISNEY</i>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f056082",
   "metadata": {},
   "source": [
    "<b> Sources :</b> <br>\n",
    "<i>https://link.springer.com/chapter/10.1007/978-3-540-30125-7_101</i> pp 818-824. 2004 - Use hue detection to detect grass (ie field) -- The results seems not usable for us <br>\n",
    "<i> https://static1.squarespace.com/static/5b048119f2e6b103db959419/t/5e99aeb4d85a234bb8752f78/1587130062444/Learning+to+track+and+identify+players+from+broadcast+sports+videos.pdf </i> Canny Edge detector to detect the field lines <br>\n",
    "<i>https://www.cse.ust.hk/~quan/comp5421/notes/canny1986.pdf</i> Paper on the Canny detector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ad1a16",
   "metadata": {},
   "source": [
    "<b>Python libraries imports</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8dd462b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'divide': 'warn', 'over': 'warn', 'under': 'ignore', 'invalid': 'warn'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import cv2\n",
    "np.seterr(invalid='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5810ee43",
   "metadata": {},
   "source": [
    "**Import the dataset of images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2111dfe0-8ef3-41df-88f2-03c01ed0079e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from skimage.io import imread\n",
    "from random import shuffle\n",
    "import scipy.io\n",
    "\n",
    "def get_image_paths(data_path, fmt='jpg'):\n",
    "    \"\"\"\n",
    "    This function returns lists containing the file path for each train \n",
    "    image, as well as lists with the label of each train image.\n",
    "    :param data_path: path to the 'train' directories\n",
    "    :param fmt: file extension of the images\n",
    "    :return: lists: train_image_paths, train_labels\n",
    "    \"\"\"\n",
    "    train_image_paths = []\n",
    "    train_labels = []\n",
    "\n",
    "    # train\n",
    "    pth = os.path.join(data_path, '*.{:s}'.format(fmt))\n",
    "    pth = glob(pth)\n",
    "    shuffle(pth)\n",
    "    train_image_paths.extend(pth)\n",
    "\n",
    "    return train_image_paths\n",
    "\n",
    "mat_1 = scipy.io.loadmat('annotation_1.mat')\n",
    "mat_1 = mat_1['annot']\n",
    "data_path = os.path.join('.', 'train')\n",
    "train_image_paths = get_image_paths(data_path)\n",
    "train_labels = mat_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4ba20d0-df95-4592-a19e-a03013052491",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import pandas as pd\n",
    "# Set up parameters, image paths\n",
    "\n",
    "df_ground_truth = pd.DataFrame(np.concatenate(mat_1))\n",
    "\n",
    "for index, row in df_ground_truth.iterrows():\n",
    "    row['ImgName'] = './train/'+row['ImgName'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4141709f-1d04-4051-b30f-b4416eca423c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BBox</th>\n",
       "      <th>ImgName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[86.0, 457.0, 116.0, 525.0], [148.0, 216.0, 1...</td>\n",
       "      <td>./train/0186.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[86, 456, 115, 524], [148, 216, 163, 258], [2...</td>\n",
       "      <td>./train/0187.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[81.0, 450.0, 120.0, 532.0], [146.0, 216.0, 1...</td>\n",
       "      <td>./train/0188.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[89.0, 455.0, 115.0, 523.0], [147.0, 218.9999...</td>\n",
       "      <td>./train/0189.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[90.0, 455.0, 114.0, 524.0], [148.0, 220.0000...</td>\n",
       "      <td>./train/0190.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1490</th>\n",
       "      <td>[[473.0, 414.99999999999994, 496.0, 481.999999...</td>\n",
       "      <td>./train/2095.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1491</th>\n",
       "      <td>[[1199.0, 516.0, 1223.0, 585.0], [1050.0, 410....</td>\n",
       "      <td>./train/2096.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1492</th>\n",
       "      <td>[[471.0, 413.0, 493.0, 481.0], [383.0, 226.0, ...</td>\n",
       "      <td>./train/2097.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1493</th>\n",
       "      <td>[[1196.0, 515.0, 1221.0, 585.0], [1043.0, 410....</td>\n",
       "      <td>./train/2098.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1494</th>\n",
       "      <td>[[468.0, 413.0, 493.0, 481.99999999999994], [3...</td>\n",
       "      <td>./train/2099.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1495 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   BBox           ImgName\n",
       "0     [[86.0, 457.0, 116.0, 525.0], [148.0, 216.0, 1...  ./train/0186.jpg\n",
       "1     [[86, 456, 115, 524], [148, 216, 163, 258], [2...  ./train/0187.jpg\n",
       "2     [[81.0, 450.0, 120.0, 532.0], [146.0, 216.0, 1...  ./train/0188.jpg\n",
       "3     [[89.0, 455.0, 115.0, 523.0], [147.0, 218.9999...  ./train/0189.jpg\n",
       "4     [[90.0, 455.0, 114.0, 524.0], [148.0, 220.0000...  ./train/0190.jpg\n",
       "...                                                 ...               ...\n",
       "1490  [[473.0, 414.99999999999994, 496.0, 481.999999...  ./train/2095.jpg\n",
       "1491  [[1199.0, 516.0, 1223.0, 585.0], [1050.0, 410....  ./train/2096.jpg\n",
       "1492  [[471.0, 413.0, 493.0, 481.0], [383.0, 226.0, ...  ./train/2097.jpg\n",
       "1493  [[1196.0, 515.0, 1221.0, 585.0], [1043.0, 410....  ./train/2098.jpg\n",
       "1494  [[468.0, 413.0, 493.0, 481.99999999999994], [3...  ./train/2099.jpg\n",
       "\n",
       "[1495 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a96e821-2752-438b-8932-9a0293ef39e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "\n",
    "H, W = 720, 1280\n",
    "N = len(df_ground_truth)\n",
    "\n",
    "def read_frame(train_image_paths, frame):\n",
    "    file_path = train_image_paths[frame]\n",
    "    img = cv2.imread(file_path,cv2.IMREAD_GRAYSCALE)\n",
    "    img = resize(img, output_shape=(H,W))\n",
    "    return img\n",
    "\n",
    "def annotations_for_frame(df_annotation, frame):\n",
    "    assert frame in df_annotation.index\n",
    "    bbs = df_annotation[df_annotation.index == frame].values[0]\n",
    "    return bbs\n",
    "\n",
    "def show_annotation(df_annotation, frame):\n",
    "    img = read_frame(df_annotation['ImgName'], frame)\n",
    "    bbs = annotations_for_frame(df_annotation['BBox'], frame)\n",
    "    fig, ax = plt.subplots(figsize=(20, 12))\n",
    "    print(type(ax))\n",
    "    for x1, y1, x2, y2 in bbs:\n",
    "        dx = x2 - x1\n",
    "        dy = y2 - y1\n",
    "        rect = patches.Rectangle((x1, y1), dx, dy, edgecolor='r', facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "    ax.imshow(img)\n",
    "    ax.set_title('Annotations for frame {}.'.format(frame))\n",
    "\n",
    "def bounding_boxes_to_mask(bounding_boxes, H, W):\n",
    "    \n",
    "    \"\"\"\n",
    "    Converts set of bounding boxes to a binary mask\n",
    "    \"\"\"\n",
    "    mask = np.zeros((H, W))\n",
    "    for x1, y1, x2, y2 in bounding_boxes:\n",
    "        dx = x2 - x1\n",
    "        dy = y2 - y1\n",
    "        mask[y1:y2,x1:x2] = 1\n",
    "    return mask\n",
    "\n",
    "def run_length_encoding(mask):\n",
    "\n",
    "    \"\"\"\n",
    "    Produces run length encoding for a given binary mask\n",
    "    \"\"\"\n",
    "    \n",
    "    # find mask non-zeros in flattened representation\n",
    "    non_zeros = np.nonzero(mask.flatten())[0]\n",
    "    padded = np.pad(non_zeros, pad_width=1, mode='edge')\n",
    "    \n",
    "    # find start and end points of non-zeros runs\n",
    "    limits = (padded[1:] - padded[:-1]) != 1\n",
    "    starts = non_zeros[limits[:-1]]\n",
    "    ends = non_zeros[limits[1:]]\n",
    "    lengths = ends - starts + 1\n",
    "    \n",
    "    return ' '.join(['%d %d' % (s, l) for s, l in zip(starts, lengths)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12512857-b438-40ad-b704-d2a7b65ae68c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c911bd7c9cef49dd886c4fb178654ad3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='frame_id', max=1493, min=1), Output()), _dom_classes=('w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.f_display_frame(frame_id)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ipywidgets import interact, widgets\n",
    "from IPython.display import display\n",
    "\n",
    "def f_display_frame(frame_id):\n",
    "    show_annotation(df_ground_truth,frame_id)\n",
    "\n",
    "interact(f_display_frame, frame_id=widgets.IntSlider(min=1, max=1493, step=1, value=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16c994b",
   "metadata": {},
   "source": [
    "## Step 1 : Canny Edge detector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c951669b",
   "metadata": {},
   "source": [
    "**We are first going to try a step by step pipeline for image preparation and the canny edge detector, inspired by the work done in assignment 1 part 2.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4182a8b5",
   "metadata": {},
   "source": [
    "**A. Smooth the image**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3aeec87a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scipy.ndimage import gaussian_filter\n",
    "smoothed = []\n",
    "\n",
    "def show_smoothed(df_annotation, frame):\n",
    "    img = read_frame(df_annotation['ImgName'], frame)\n",
    "    smoothed_ = gaussian_filter(img, sigma=2)\n",
    "    smoothed.append(smoothed_)\n",
    "    fig, axes = plt.subplots(figsize=(20, 12), ncols=2)\n",
    "    axes[0].imshow(img) \n",
    "    axes[1].imshow(smoothed_)\n",
    "    \n",
    "    bbs = annotations_for_frame(df_annotation['BBox'], frame)\n",
    "    for x1, y1, x2, y2 in bbs:\n",
    "        dx = x2 - x1\n",
    "        dy = y2 - y1\n",
    "        rect = patches.Rectangle((x1, y1), dx, dy, edgecolor='r', facecolor='none')\n",
    "        axes[0].add_patch(rect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afbeabbf-06d1-42a4-a371-262f410d7886",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae3b7b3b4d6d476180610e4c0383d3c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='frame_id', max=853, min=1), Output()), _dom_classes=('wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.f_display_smoothed(frame_id)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f_display_smoothed(frame_id):\n",
    "    show_smoothed(df_ground_truth,frame_id)\n",
    "\n",
    "interact(f_display_smoothed, frame_id=widgets.IntSlider(min=1, max=853, step=1, value=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9367ea20",
   "metadata": {},
   "source": [
    "**B. Gradients**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1e2b0d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from skimage.filters import sobel \n",
    "\n",
    "gradient_g_magnitude = []\n",
    "gradient_g_dir = []\n",
    "\n",
    "def gradient(img):\n",
    "    g_x = sobel(img, axis=1) \n",
    "    g_y = sobel(img, axis=0)\n",
    "    g_mag = np.sqrt(g_x**2 + g_y**2) \n",
    "    g_dir = np.arctan(g_y / g_x)\n",
    "    return g_mag, g_dir\n",
    "\n",
    "def show_gradient(df_annotation, frame):\n",
    "    img = read_frame(df_annotation['ImgName'], frame)\n",
    "    smoothed_ = gaussian_filter(img, sigma=2)\n",
    "    g_magnitude, g_dir = gradient(smoothed_)\n",
    "    gradient_g_magnitude.append(g_magnitude)\n",
    "    gradient_g_dir.append(g_dir)\n",
    "    fig, axes = plt.subplots(figsize=(20, 12), ncols=2)\n",
    "    axes[0].imshow(g_magnitude) \n",
    "    axes[1].imshow(g_dir)\n",
    "    \n",
    "    bbs = annotations_for_frame(df_annotation['BBox'], frame)\n",
    "    for x1, y1, x2, y2 in bbs:\n",
    "        dx = x2 - x1\n",
    "        dy = y2 - y1\n",
    "        rect = patches.Rectangle((x1, y1), dx, dy, edgecolor='r', facecolor='none')\n",
    "        axes[0].add_patch(rect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2a1cc88-993d-4b35-b4e5-b681117f4a98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "227c74dca9784a7e88b36fa21b5a8439",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='frame_id', max=853, min=1), Output()), _dom_classes=('wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.f_display_gradient(frame_id)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f_display_gradient(frame_id):\n",
    "    show_gradient(df_ground_truth,frame_id)\n",
    "\n",
    "interact(f_display_gradient, frame_id=widgets.IntSlider(min=1, max=853, step=1, value=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2698da14",
   "metadata": {},
   "source": [
    "**C. Non-maximum suppression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f80906c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def non_maximum_suppression(g_magnitude, g_dir):\n",
    "    #quantise the gradient directions into 4 values np.array([0, np.pi/4, np.pi/2, 3*np.pi/4])\n",
    "    h, w = g_magnitude.shape \n",
    "    values = np.array([0, np.pi, np.pi/4, np.pi/2, 3*np.pi/4])\n",
    "    g_max = np.zeros_like(g_magnitude)\n",
    "    for i in range(h-1):\n",
    "        for j in range(w-1):\n",
    "            diff = abs(values - g_dir[i,j])\n",
    "            angle = values[np.argmin(diff)]\n",
    "            q = 0\n",
    "            r = 0\n",
    "            #case angle = 0\n",
    "            if angle == 0 or angle == 1 :\n",
    "                q = g_magnitude[i, j+1]\n",
    "                r = g_magnitude[i, j-1]\n",
    "            #case angle = pi/4\n",
    "            elif angle == 2:\n",
    "                q = g_magnitude[i+1, j-1]\n",
    "                r = g_magnitude[i-1, j+1]\n",
    "            #case angle = pi/2 \n",
    "            elif angle == 3:\n",
    "                q = g_magnitude[i+1, j]\n",
    "                r = g_magnitude[i-1, j]\n",
    "            #case angle = 3pi/4\n",
    "            else:\n",
    "                q = g_magnitude[i-1, j-1]\n",
    "                r = g_magnitude[i+1, j+1]\n",
    "                \n",
    "            if g_magnitude[i,j] >= q and g_magnitude[i,j]>=r : \n",
    "                g_max[i,j] = g_magnitude[i,j]\n",
    "            else:\n",
    "                g_max[i,j] = 0\n",
    "\n",
    "    return g_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f3ee78d-d228-49a1-b690-846612b4c09a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "111380672fba4f51a5b3dae9335e2c93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='frame_id', max=853, min=1), Output()), _dom_classes=('wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.f_display_non_maximum_suppression(frame_id)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def show_non_maximum_suppression(df_annotation, frame):\n",
    "    img = read_frame(df_annotation['ImgName'], frame)\n",
    "    smoothed_ = gaussian_filter(img, sigma=2)\n",
    "    g_magnitude, g_dir = gradient(smoothed_)\n",
    "    g_max = non_maximum_suppression(g_magnitude, g_dir)\n",
    "    fig, axes = plt.subplots(figsize=(20, 12), ncols=2)\n",
    "    axes[0].imshow(g_max, cmap='gray')\n",
    "    axes[1].imshow(g_magnitude - g_max, cmap='gray')\n",
    "    \n",
    "    bbs = annotations_for_frame(df_annotation['BBox'], frame)\n",
    "    for x1, y1, x2, y2 in bbs:\n",
    "        dx = x2 - x1\n",
    "        dy = y2 - y1\n",
    "        rect = patches.Rectangle((x1, y1), dx, dy, edgecolor='r', facecolor='none')\n",
    "        axes[0].add_patch(rect)\n",
    "        \n",
    "def f_display_non_maximum_suppression(frame_id):\n",
    "    show_non_maximum_suppression(df_ground_truth,frame_id)\n",
    "    \n",
    "interact(f_display_non_maximum_suppression, frame_id=widgets.IntSlider(min=1, max=853, step=1, value=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec20a0c",
   "metadata": {},
   "source": [
    "**D. Double Thresholding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a2c519d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def double_thresholding(g_max, thresh_lo, thresh_hi):\n",
    "    h, w = g_max.shape\n",
    "    thresh_img = np.zeros_like(g_max)\n",
    "    highThreshold = g_max.max() * thresh_hi;\n",
    "    lowThreshold = highThreshold * thresh_lo;\n",
    "    \n",
    "    for i in range(h):\n",
    "        for j in range(w):\n",
    "            if g_max[i,j] > highThreshold :\n",
    "                 thresh_img[i,j] = 1\n",
    "            elif g_max[i,j] > lowThreshold:\n",
    "                thresh_img[i,j] = 0.25\n",
    "\n",
    "    return thresh_img\n",
    "\n",
    "def show_double_thresholding(df_annotation, frame):\n",
    "    img = read_frame(df_annotation['ImgName'], frame)\n",
    "    smoothed_ = gaussian_filter(img, sigma=2)\n",
    "    g_magnitude, g_dir = gradient(smoothed_)\n",
    "    g_max = non_maximum_suppression(g_magnitude, g_dir)\n",
    "    thresh_img = double_thresholding(g_max, thresh_lo=0.05, thresh_hi=0.08)\n",
    "    fig, ax = plt.subplots(figsize=(12, 12))\n",
    "    ax.imshow(thresh_img)\n",
    "    \n",
    "    bbs = annotations_for_frame(df_annotation['BBox'], frame)\n",
    "    for x1, y1, x2, y2 in bbs:\n",
    "        dx = x2 - x1\n",
    "        dy = y2 - y1\n",
    "        rect = patches.Rectangle((x1, y1), dx, dy, edgecolor='r', facecolor='none')\n",
    "        ax.add_patch(rect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "28c8b290-0602-4d10-a60e-3511854f9f2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a11d62fdb22146a6afbe8ff37ae88c36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='frame_id', max=853, min=1), Output()), _dom_classes=('wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.f_double_thresholding(frame_id)>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f_double_thresholding(frame_id):\n",
    "    show_double_thresholding(df_ground_truth,frame_id)\n",
    "    \n",
    "interact(f_double_thresholding, frame_id=widgets.IntSlider(min=1, max=853, step=1, value=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ddc68de",
   "metadata": {},
   "source": [
    "**E. Edge connectivity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9439fde0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def connectivity(thresh_img):\n",
    "    h, w = thresh_img.shape\n",
    "    edge_img = thresh_img\n",
    "    \n",
    "    for i in range(h):\n",
    "        for j in range(w):\n",
    "            if edge_img[i,j] == 0.25:\n",
    "                if edge_img[i+1,j] == 1 or edge_img[i+1,j+1] == 1 or edge_img[i,j+1] == 1 or edge_img[i-1,j] == 1 or edge_img[i-1,j-1] == 1 or edge_img[i,j-1] == 1 or edge_img[i+1,j-1] == 1 or edge_img[i-1,j+1] == 1:\n",
    "                    edge_img[i,j] = 1 \n",
    "                else:\n",
    "                    edge_img[i,j] = 0\n",
    "\n",
    "    return edge_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a7d51500-48e2-4762-bce4-2f4e36e62e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_connectivity(df_annotation, frame):\n",
    "    img = read_frame(df_annotation['ImgName'], frame)\n",
    "    smoothed_ = gaussian_filter(img, sigma=2)\n",
    "    g_magnitude, g_dir = gradient(smoothed_)\n",
    "    g_max = non_maximum_suppression(g_magnitude, g_dir)\n",
    "    thresh_img = double_thresholding(g_max, thresh_lo=0.05, thresh_hi=0.08)\n",
    "    edge_img = connectivity(thresh_img)\n",
    "    fig, ax = plt.subplots(figsize=(12, 12))\n",
    "    ax.imshow(edge_img, cmap='gray')\n",
    "    \n",
    "    bbs = annotations_for_frame(df_annotation['BBox'], frame)\n",
    "    for x1, y1, x2, y2 in bbs:\n",
    "        dx = x2 - x1\n",
    "        dy = y2 - y1\n",
    "        rect = patches.Rectangle((x1, y1), dx, dy, edgecolor='r', facecolor='none')\n",
    "        ax.add_patch(rect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1910a86c-2145-46b8-9bb6-7399d8994d1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d64e6654a4e4a8898aaf300d2e47521",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='frame_id', max=853, min=1), Output()), _dom_classes=('wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.f_double_connectivity(frame_id)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f_double_connectivity(frame_id):\n",
    "    show_connectivity(df_ground_truth,frame_id)\n",
    "    \n",
    "interact(f_double_connectivity, frame_id=widgets.IntSlider(min=1, max=853, step=1, value=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdaf1ac",
   "metadata": {},
   "source": [
    "#### Canny detector Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9270d063",
   "metadata": {},
   "outputs": [],
   "source": [
    "def canny_edge_detector(img, thresh_lo=0.1, thresh_hi=0.2):\n",
    "    \"\"\"\n",
    "    The Canny edge detector.\n",
    "    \n",
    "    Inputs:\n",
    "        img              The input image\n",
    "        thresh_lo        The fraction of the maximum gradient magnitude which will \n",
    "                         be considered the lo threshold. \n",
    "        thresh_hi        The fraction of the maximum gradient magnitude which will\n",
    "                         be considered the hi threshold. Ideally should be 2x to 3x \n",
    "                         thresh_lo.\n",
    "                         \n",
    "    Outputs: \n",
    "        edge_img         A binary image, with pixels lying on edges marked with a 1, \n",
    "                         and others with a 0.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Smooth the image first. \n",
    "    smoothed             = gaussian_filter(img,2)\n",
    "    \n",
    "    # Find gradient magnitude and direction\n",
    "    g_magnitude, g_dir   = gradient(smoothed)\n",
    "    \n",
    "    # Non-maximum suppression\n",
    "    g_max                = non_maximum_suppression(g_magnitude, g_dir)\n",
    "    \n",
    "    # Double thresholding\n",
    "    thresh_img           = double_thresholding(g_max, thresh_lo, thresh_hi)\n",
    "    \n",
    "    # Final edge connectivity\n",
    "    edge_img             = connectivity(thresh_img)\n",
    "    \n",
    "    # Return the result\n",
    "    return edge_img\n",
    "\n",
    "def show_canny_edge_detector(df_annotation, frame):\n",
    "    img = read_frame(df_annotation['ImgName'], frame)\n",
    "    edges = canny_edge_detector(img, thresh_lo=0.05, thresh_hi=0.09)\n",
    "    fig, axes = plt.subplots(figsize=(20, 12), ncols=2)\n",
    "    axes[0].imshow(img, cmap='gray')\n",
    "    axes[1].imshow(edges, cmap='gray')\n",
    "    \n",
    "    bbs = annotations_for_frame(df_annotation['BBox'], frame)\n",
    "    for x1, y1, x2, y2 in bbs:\n",
    "        dx = x2 - x1\n",
    "        dy = y2 - y1\n",
    "        rect = patches.Rectangle((x1, y1), dx, dy, edgecolor='r', facecolor='none')\n",
    "        axes[0].add_patch(rect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6276cc0a-3e52-415b-9c07-dd0e2189fc9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b7ac9bf100b4166a907bd3d32b43dff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='frame_id', max=853, min=1), Output()), _dom_classes=('wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.f_canny_edge_detector(frame_id)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f_canny_edge_detector(frame_id):\n",
    "    show_canny_edge_detector(df_ground_truth,frame_id)\n",
    "    \n",
    "interact(f_canny_edge_detector, frame_id=widgets.IntSlider(min=1, max=853, step=1, value=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4778fd7b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Next step:</b> Here, you can see that the players are noising the detections of the fields'line, in the Lu's Paper they decided to detect the bounding boxes of the players to delete them from the edge detection. This is what we are going to try to do next.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a5b514",
   "metadata": {},
   "source": [
    "### Find the players on the field\n",
    "Main ref paper : http://cs.brown.edu/people/pfelzens/papers/latent.pdf (seen in course)\n",
    "\n",
    "https://www.cs.toronto.edu/~fidler/slides/2015/CSC420/lecture19.pdf (course on DPM detector -- based on Hog detector)\n",
    "\n",
    "http://ipl.ce.sharif.edu/azadi_soccer_dataset.html (dataset 1 -- emailed the owner)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f548ce18",
   "metadata": {},
   "source": [
    "**First we try a classic HOG + SVM from opencv**\n",
    "The DPM model starts by borrowing the idea of the HOG detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a03325dc-4578-4fe0-9ffc-35c493794155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imutils in /Users/famille.laisney/opt/anaconda3/lib/python3.9/site-packages (0.5.4)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bf987c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imutils.object_detection import non_max_suppression\n",
    "import argparse\n",
    "import imutils\n",
    "\n",
    "# initialize the HOG descriptor/person detector\n",
    "hog = cv2.HOGDescriptor()\n",
    "hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
    "\n",
    "#image = imutils.resize(image, height = 350, width=625)\n",
    "#image = resize(img, output_shape=(350, 625))\n",
    "orig = image.copy()\n",
    "# detect people in the image\n",
    "(rects, weights) = hog.detectMultiScale(image, winStride=(5, 5), scale = 1.01)\n",
    "# draw the original bounding boxes\n",
    "for (x, y, w, h) in rects:\n",
    "    cv2.rectangle(orig, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "# apply non-maxima suppression to the bounding boxes using a\n",
    "# fairly large overlap threshold to try to maintain overlapping\n",
    "# boxes that are still people\n",
    "rects = np.array([[x, y, x + w, y + h] for (x, y, w, h) in rects])\n",
    "pick = non_max_suppression(rects, probs=None, overlapThresh=0.9)\n",
    "# draw the final bounding boxes\n",
    "for (xA, yA, xB, yB) in pick:\n",
    "    cv2.rectangle(image, (xA, yA), (xB, yB), (0, 255, 0), 2)\n",
    "# show some information on the number of bounding boxes\n",
    "print(\"[INFO]: {} original boxes, {} after suppression\".format(\n",
    "     len(rects), len(pick)))\n",
    "\n",
    "# show the output images\n",
    "fig, axes = plt.subplots(figsize=(20, 12), ncols=2)\n",
    "axes[0].imshow(orig, cmap='gray')\n",
    "axes[1].imshow(image, cmap='gray')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2dd7bd8",
   "metadata": {},
   "source": [
    "**Let's code a Hog detector**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b988edb-4368-46cb-b9bb-344dbb05054b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window(image, window_size, step_size=8):\n",
    "    # slide a window across the image\n",
    "    for y in range(0, image.shape[0], step_size):\n",
    "        for x in range(0, image.shape[1], step_size):\n",
    "            # yield the current window\n",
    "            window = image[y:y + window_size[1], x:x + window_size[0]]\n",
    "            if not (window.shape[0] != window_size[1] or window.shape[1] != window_size[0]):\n",
    "                yield (x, y, window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef63fd1-5225-44e1-910a-54c474c2204f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the image, convert it to grayscale, dand detect edges\n",
    "winStride = (8, 8)  \n",
    "padding = (8, 8)\n",
    "locations = ((10,20),)\n",
    "\n",
    "data = []   # Feature vectors\n",
    "labels = [] # Label for each feature vector\n",
    "(winW, winH) = (200, 100) # Window size for images\n",
    "min_loss = 10.0 # Min loss so that a result is considered valid\n",
    "\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "edged = imutils.auto_canny(gray)\n",
    "contours, hierarchy = cv2.findContours(edged, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)[-2:]\n",
    "c = max(contours, key=cv2.contourArea)\n",
    "H = hog.compute(image,winStride,padding,locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884adcb1-6fa9-4e4a-9231-8d40c8b19627",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.append(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8735a903-b2e5-4898-91e5-c5af387ec063",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
